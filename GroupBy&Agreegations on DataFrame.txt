
// creating spark session 
import org.apache.spark.sql.SparkSession
val spark = SparkSession.builder().getOrCreate()

// Create a DataFrame from Spark Session read csv
// Technically known as class Dataset
val df = spark.read.option("header","true").option("inferSchema","true").csv("CitiGroup2006_2008.csv")

// Show Schema
df.printSchema()

//df.show()

df.groupBy("Company").mean().show()

df.groupBy("Company").count().show()

df.groupBy("Company").max().show()

df.groupBy("Company").min().show()

df.groupBy("Company").sum().show()



// Other Aggregate Functions
// http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$
df.select(countDistinct("Sales")).show() //approxCountDistinct
df.select(sumDistinct("Sales")).show()
df.select(variance("Sales")).show()
df.select(stddev("Sales")).show() //avg,max,min,sum,stddev
df.select(collect_set("Sales")).show()


df.orderBy("Sales").show()

df.orderBy($"Sales".desc).show()


// Dealing with Missing Data in DataFrame
val df = spark.read.option("header","true").option("inferSchema","true").csv("ContainsNull.csv")

df.printSchema()

 df.show()


//df.na.drop().show()

// deleting the row which contains two null values
df.na.drop(2).show()

// fill the missing values with numerical values in numerical columns
df.na.fill(100).show()

// fill the missing values as string's in string type columns
df.na.fill("Missing Name").show()

// df.na.fill("New Name",Array("Name")).show()

// filling both the columns
  val df2 = df.na.fill("New Name",Array("Name"))

 df2.na.fill(200,Array("Sales")).show()



// TimeStamps operations on DataFrame

df.select(month(df("Date"))).show()

df.select(year(df("Date"))).show()

val df2 = df.withColumn("Year", year(df("Date")))

val dfmins = df2.groupBy("year").min()

dfmins.select($"Year", $"min(Close)").show()
